{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "from sklearn.decomposition import PCA\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadarff('electricity-normalized.arff')\n",
    "df = pd.DataFrame(raw_data[0])\n",
    "df['target'] = np.where(df['class'] == b'UP', 1, 0)\n",
    "df = pd.get_dummies(df.drop(columns='class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45312 entries, 0 to 45311\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   date       45312 non-null  float64\n",
      " 1   period     45312 non-null  float64\n",
      " 2   nswprice   45312 non-null  float64\n",
      " 3   nswdemand  45312 non-null  float64\n",
      " 4   vicprice   45312 non-null  float64\n",
      " 5   vicdemand  45312 non-null  float64\n",
      " 6   transfer   45312 non-null  float64\n",
      " 7   target     45312 non-null  int64  \n",
      " 8   day_b'1'   45312 non-null  uint8  \n",
      " 9   day_b'2'   45312 non-null  uint8  \n",
      " 10  day_b'3'   45312 non-null  uint8  \n",
      " 11  day_b'4'   45312 non-null  uint8  \n",
      " 12  day_b'5'   45312 non-null  uint8  \n",
      " 13  day_b'6'   45312 non-null  uint8  \n",
      " 14  day_b'7'   45312 non-null  uint8  \n",
      "dtypes: float64(7), int64(1), uint8(7)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date**: date between 7 May 1996 to 5 December 1998. Here normalized between 0 and 1\n",
    "\n",
    "**Day**: day of the week (1-7)\n",
    "\n",
    "**Period**: time of the measurement (1-48) in half hour intervals over 24 hours. Here normalized between 0 and 1\n",
    "\n",
    "**NSWprice**: New South Wales electricity price, normalized between 0 and 1\n",
    "\n",
    "**NSWdemand**: New South Wales electricity demand, normalized between 0 and 1\n",
    "\n",
    "**VICprice**: Victoria electricity price, normalized between 0 and 1\n",
    "\n",
    "**VICdemand**: Victoria electricity demand, normalized between 0 and 1\n",
    "\n",
    "**transfer**: scheduled electricity transfer between both states, normalized between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.37229263333418\n",
      "97.65797924750096\n",
      "77.65509729067612\n"
     ]
    }
   ],
   "source": [
    "first = df.query('date < 0.45')\n",
    "second = df.query('date > 0.98')\n",
    "v1 = np.sqrt(np.sum((scipy.linalg.svdvals(first) - scipy.linalg.svdvals(second))**2))\n",
    "U, S, VT = la.svd(first)\n",
    "U_s, S_s, VT_s = la.svd(second)\n",
    "print(v1)\n",
    "\n",
    "first = df.query('date < 0.45')\n",
    "second = df.query('date > 0.90')\n",
    "v2 = np.sqrt(np.sum((scipy.linalg.svdvals(first) - scipy.linalg.svdvals(second))**2))\n",
    "print(v2)\n",
    "\n",
    "first = df.query('date < 0.60')\n",
    "second = df.query('date > 0.60 and date < 0.90')\n",
    "U, S, VT = la.svd(first)\n",
    "U_s, S_s, VT_s = la.svd(second)\n",
    "v3 = np.sqrt(np.sum((scipy.linalg.svdvals(first) - scipy.linalg.svdvals(second))**2))\n",
    "print(v3)\n",
    "\n",
    "first = df.query('date < 0.45')\n",
    "second = df.query('date > 0.90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24, -0.46, -0.05, -0.37, -0.  , -0.35, -0.38, -0.46, -0.12,\n",
       "       -0.12, -0.12, -0.12, -0.12, -0.12, -0.11])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(VT[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.59, -0.36, -0.04, -0.32, -0.  , -0.31, -0.4 , -0.33, -0.09,\n",
       "       -0.09, -0.1 , -0.1 , -0.1 , -0.1 , -0.1 ])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(VT_s[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196151271197981\n",
      "0.924274411102636\n",
      "-0.832632420087531\n",
      "0.014504586130451452\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(VT_s[0], VT[0]))\n",
    "print(np.dot(VT_s[1], VT[1]))\n",
    "print(np.dot(VT_s[2], VT[2]))\n",
    "print(np.dot(VT_s[3], VT[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9196151271197981\n",
      "0.924274411102636\n",
      "-0.832632420087531\n",
      "0.014504586130451452\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(VT_s[0], VT[0]))\n",
    "print(np.dot(VT_s[1], VT[1]))\n",
    "print(np.dot(VT_s[2], VT[2]))\n",
    "print(np.dot(VT_s[3], VT[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = first.drop(columns=['target', 'date'])\n",
    "y = first['target']\n",
    "weights = la.inv(X.T @ X) @ X.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = second.drop(columns=['target', 'date'])\n",
    "test_y = second['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.index = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nswprice</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nswdemand</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicprice</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicdemand</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transfer</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'1'</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'2'</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'3'</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'4'</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'5'</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'6'</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_b'7'</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           first  second\n",
       "date        0.01   -0.05\n",
       "period      0.17    0.11\n",
       "nswprice    0.58    0.54\n",
       "nswdemand   0.34    0.41\n",
       "vicprice    0.21    0.15\n",
       "vicdemand   0.15    0.38\n",
       "transfer   -0.09   -0.17\n",
       "target      1.00    1.00\n",
       "day_b'1'    0.07    0.01\n",
       "day_b'2'   -0.01    0.14\n",
       "day_b'3'   -0.02    0.00\n",
       "day_b'4'   -0.01   -0.04\n",
       "day_b'5'   -0.02   -0.01\n",
       "day_b'6'   -0.01   -0.02\n",
       "day_b'7'   -0.01   -0.08"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_compare = pd.DataFrame({'first':first.corr().round(2)['target'], 'second':second.corr().round(2)['target']})\n",
    "corr_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.loc['vicdemand'] *= 1.23\n",
    "# weights.loc[\"day_b'2'\"] *= 1.23\n",
    "pred_y = test_X.values @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.8180423594615994\n",
      "test error: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"train error: {np.mean(np.where(X.values @ weights < 0.5, 0, 1) == y)}\")\n",
    "print(f\"test error: {np.mean(np.where(pred_y < 0.5, 0, 1) == test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using resampling approaches at the data drift point \n",
    "\n",
    "1. The case where we are doing the data analysis in real time. Retrain the model with more weight on the most recent data?\n",
    "2. The case where we have SOME of the test values but not all of them. Once again we can train on these with higher weights on these samples. \n",
    "3. Use the PCA and K-Means approach?\n",
    "\n",
    "\n",
    "**How does Sklearn implement their sample weighting?**\n",
    "\n",
    "- I think one approach is to make a new loss function where it is disjoint? \n",
    "- Another approach for this project is making probabilities more uncertain for drifted data and comparing the log-loss of this function compared to the regular one. The theory predicts that higher uncertainity should lead to a better loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "first_x = pca.fit_transform(first.iloc[:,:4])\n",
    "second_x = pca.fit_transform(second.iloc[:,:4])\n",
    "# second_x_test = pca.fit_transform(second_test.iloc[:,:4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8690373d696fc6b9ca58c0b6b800c7f480b19699746d2dc5c9c0d4031bb8f2b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
